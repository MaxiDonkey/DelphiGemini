unit Gemini.Chat.Request.GenerationConfig;

{-------------------------------------------------------------------------------

      Github repository :  https://github.com/MaxiDonkey/DelphiGemini
      Visit the Github repository for the documentation and use examples

 ------------------------------------------------------------------------------}

interface

{$REGION 'dev note'}

(*

  Delphi code to JSON when TGenerationConfig used

  1 SpeechConfig
  --------------

  TChatParams.Create
    .GenerationConfig(
      TGenerationConfig.Create
        .SpeechConfig(
          TSpeechConfig.Create
            .VoiceConfig(
              TVoiceConfig.NewVoiceConfig('the voice')
              )
            .MultiSpeakerVoiceConfig(
              TMultiSpeakerVoiceConfig.Create
                .SpeakerVoiceConfigs(
                  TSpeakerVoice.Create
                    .AddSpeakerVoiceConfig('speaker-2', 'voice-2')
                    .AddSpeakerVoiceConfig('speaker-3', 'voice-3')
                  )
              )
             .LanguageCode('fr-FR')
          )
        );

  JSON result:

  {
    "generationConfig": {
        "speechConfig": {
            "voiceConfig": {
                "prebuiltVoiceConfig": {
                    "voiceName": "the voice"
                }
            },
            "multiSpeakerVoiceConfig": {
                "speakerVoiceConfigs": [
                    {
                        "speaker": "speaker-2",
                        "voiceConfig": {
                            "prebuiltVoiceConfig": {
                                "voiceName": "voice-2"
                            }
                        }
                    },
                    {
                        "speaker": "speaker-3",
                        "voiceConfig": {
                            "prebuiltVoiceConfig": {
                                "voiceName": "voice-3"
                            }
                        }
                    }
                ]
            },
            "languageCode": "fr-FR"
        }
    }
  }

  ------------------------------------------------------------------------------

  2. ImageConfig

  TChatParams.Create
    .GenerationConfig(
      TGenerationConfig.Create
        .ImageConfig(
          TImageConfig.Create
            .AspectRatio('2:3')
            .ImageSize('4k')
          )
      );

  JSON result:

  {
    "generationConfig": {
        "imageConfig": {
            "aspectRatio": "2:3",
            "imageSize": "4k"
        }
    }
  }

  ------------------------------------------------------------------------------

  3. ThinkingConfig

  TChatParams.Create
    .GenerationConfig(
      TGenerationConfig.Create
        .ThinkingConfig(
           TThinkingConfig.Create
             .IncludeThoughts(True)
             .ThinkingBudget(5)
             .ThinkingLevel(TThinkingLevelType.HIGH)
        )
      );

  JSON result:

  {
    "generationConfig": {
        "thinkingConfig": {
            "includeThoughts": true,
            "thinkingBudget": 5,
            "thinkingLevel": "HIGH"
        }
    }
  }


*)

{$ENDREGION}

uses
  System.JSON, Gemini.API.Params,Gemini.Types, Gemini.Schema, Gemini.Exceptions;

type
  TPrebuiltVoiceConfig = class(TJSONParam)
    /// <summary>
    /// The name of the preset voice to use.
    /// </summary>
    function VoiceName(const Value: string): TPrebuiltVoiceConfig;
  end;

  TVoiceConfig = class(TJSONParam)
    /// <summary>
    /// The configuration for the prebuilt voice to use.
    /// </summary>
   function PrebuiltVoiceConfig(const Value: TPrebuiltVoiceConfig): TVoiceConfig;

   class function NewVoiceConfig(const VoiceName: string): TVoiceConfig;
  end;

  TSpeakerVoiceConfig =  class(TJSONParam)
    /// <summary>
    /// Required. The name of the speaker to use. Should be the same as in the prompt.
    /// </summary>
    function Speaker(const Value: string): TSpeakerVoiceConfig;

    /// <summary>
    /// Required. The configuration for the voice to use.
    /// </summary>
    function VoiceConfig(const Value: TVoiceConfig): TSpeakerVoiceConfig;

    class function NewSpeakerVoiceConfig(const Speaker: string; const VoiceConfig: TVoiceConfig): TSpeakerVoiceConfig; overload;
    class function NewSpeakerVoiceConfig(const Speaker: string; const VoiceName: string): TSpeakerVoiceConfig; overload;
  end;

  TMultiSpeakerVoiceConfig = class(TJSONParam)
    /// <summary>
    /// Required. All the enabled speaker voices.
    /// </summary>
    function SpeakerVoiceConfigs(const Value: TArray<TSpeakerVoiceConfig>): TMultiSpeakerVoiceConfig;

  end;

  TSpeechConfig = class(TJSONParam)
    /// <summary>
    /// The configuration in case of single-voice output.
    /// </summary>
    function VoiceConfig(const Value: TVoiceConfig): TSpeechConfig;

    /// <summary>
    /// Optional. The configuration for the multi-speaker setup. It is mutually exclusive with the voiceConfig field.
    /// </summary>
    function MultiSpeakerVoiceConfig(const Value: TMultiSpeakerVoiceConfig): TSpeechConfig;

    /// <summary>
    /// Optional. Language code (in BCP 47 format, e.g. "en-US") for speech synthesis.
    /// </summary>
    /// <param name="Value">
    /// Valid values are: de-DE, en-AU, en-GB, en-IN, en-US, es-US, fr-FR, hi-IN, pt-BR, ar-XA, es-ES,
    /// fr-CA, id-ID, it-IT, ja-JP, tr-TR, vi-VN, bn-IN, gu-IN, kn-IN, ml-IN, mr-IN, ta-IN, te-IN, nl-NL,
    /// ko-KR, cmn-CN, pl-PL, ru-RU, and th-TH.
    /// </param>
    function LanguageCode(const Value: string): TSpeechConfig;
  end;

  TThinkingConfig = class(TJSONParam)
    /// <summary>
    /// Indicates whether to include thoughts in the response. If true, thoughts are returned only when available.
    /// </summary>
    function IncludeThoughts(const Value: Boolean): TThinkingConfig;

    /// <summary>
    /// The number of thoughts tokens that the model should generate.
    /// </summary>
    function ThinkingBudget(const Value: Integer): TThinkingConfig;

    /// <summary>
    /// Optional. Controls the maximum depth of the model's internal reasoning process before it produces
    /// a response.
    /// </summary>
    /// <remarks>
    /// <para>
    /// • If not specified, the default is HIGH. Recommended for Gemini 3 or later models.
    /// </para>
    /// • Use with earlier models results in an error.
    /// </remarks>
    function ThinkingLevel(const Value: TThinkingLevelType): TThinkingConfig;
  end;

  TImageConfig = class(TJSONParam)
    /// <summary>
    /// Optional. The aspect ratio of the image to generate.
    /// </summary>
    /// <param name="Value">
    /// Supported aspect ratios: 1:1, 2:3, 3:2, 3:4, 4:3, 9:16, 16:9, 21:9.
    /// </param>
    /// <remarks>
    /// If not specified, the model will choose a default aspect ratio based on any reference images provided.
    /// </remarks>
    function AspectRatio(const Value: string): TImageConfig;

    /// <summary>
    /// Optional. Specifies the size of generated images.
    /// </summary>
    /// <param name="Value">
    /// Supported values are 1K, 2K, 4K.
    /// </param>
    /// <remarks>
    /// If not specified, the model will use default value 1K.
    /// </remarks>
    function ImageSize(const Value: string): TImageConfig;
  end;

  /// <summary>
  /// Represents the configuration options for generating model outputs in a chat or completion request.
  /// </summary>
  /// <remarks>
  /// The <c>TGenerationConfig</c> class allows you to specify various parameters that control the behavior of the AI model during text generation.
  /// These settings can influence the randomness, length, and format of the generated responses.
  /// Not all parameters are configurable for every model; some models may ignore certain settings.
  /// </remarks>
  TGenerationConfig = class(TJSONParam)
  public
    /// <summary>
    /// Optional. The set of character sequences (up to 5) that will stop output generation. If specified,
    /// the API will stop at the first appearance of a stop_sequence. The stop sequence will not be included
    /// as part of the response.
    /// </summary>
    function StopSequences(const Value: TArray<string>): TGenerationConfig;

    /// <summary>
    /// Optional. MIME type of the generated candidate text. Supported MIME types are:
    /// text/plain: (default) Text output. application/json: JSON response in the response candidates.
    /// text/x.enum: ENUM as a string response in the response candidates.
    /// </summary>
    /// <remarks>
    /// Refer to the docs for a list of all supported text MIME types.
    /// </remarks>
    function ResponseMimeType(const Value: string): TGenerationConfig;

    /// <summary>
    /// Optional. Output schema of the generated candidate text. Schemas must be a subset of the OpenAPI
    /// schema and can be objects, primitives or arrays.
    /// </summary>
    /// <remarks>
    /// If set, a compatible responseMimeType must also be set. Compatible MIME types: application/json:
    /// Schema for JSON response.
    /// <para>
    /// • Refer to the JSON text generation guide for more details.
    /// </para>
    /// <para>
    /// • https://ai.google.dev/gemini-api/docs/json-mode
    /// </para>
    /// </remarks>
    function ResponseSchema(const Value: TSchemaParams): TGenerationConfig; overload;

    /// <summary>
    /// Optional. Output schema of the generated candidate text. Schemas must be a subset of the OpenAPI
    /// schema and can be objects, primitives or arrays.
    /// </summary>
    /// <remarks>
    /// If set, a compatible responseMimeType must also be set. Compatible MIME types: application/json:
    /// Schema for JSON response.
    /// <para>
    /// • Refer to the JSON text generation guide for more details.
    /// </para>
    /// <para>
    /// • https://ai.google.dev/gemini-api/docs/json-mode
    /// </para>
    /// </remarks>
    function ResponseSchema(const Value: TJSONObject): TGenerationConfig; overload;

    /// <summary>
    /// Optional. Output schema of the generated candidate text. Schemas must be a subset of the OpenAPI
    /// schema and can be objects, primitives or arrays.
    /// </summary>
    /// <remarks>
    /// If set, a compatible responseMimeType must also be set. Compatible MIME types: application/json:
    /// Schema for JSON response.
    /// <para>
    /// • Refer to the JSON text generation guide for more details.
    /// </para>
    /// <para>
    /// • https://ai.google.dev/gemini-api/docs/json-mode
    /// </para>
    /// </remarks>
    function ResponseSchema(const Value: string): TGenerationConfig; overload;

    /// <summary>
    /// Optional. The requested modalities of the response.
    /// <para>
    /// • Represents the set of modalities that the model can return, and should be expected in the response.
    /// This is an exact match to the
    /// modalities of the response.
    /// </para>
    /// </summary>
    /// <remarks>
    /// <para>
    /// • A model may have multiple combinations of supported modalities. If the requested modalities
    /// do not match any of the supported combinations, an error will be returned.
    /// </para>
    /// <para>
    /// • An empty list is equivalent to requesting only text.
    /// </para>
    /// </remarks>
    function ResponseModalities(const Value: TArray<TModalityType>): TGenerationConfig;

    /// <summary>
    /// Optional. Number of generated responses to return. If unset, this will default to 1.
    /// </summary>
    /// <remarks>
    /// Please note that this doesn't work for previous generation models (Gemini 1.0 family)
    /// </remarks>
    function CandidateCount(const Value: Integer): TGenerationConfig;

    /// <summary>
    /// Optional. The maximum number of tokens to include in a response candidate.
    /// </summary>
    /// <remarks>
    /// TNote: The default value varies by model, see the Model.output_token_limit attribute of the Model
    /// returned from the getModel function.
    /// </remarks>
    function MaxOutputTokens(const Value: Integer): TGenerationConfig;

    /// <summary>
    /// Optional. Controls the randomness of the output.
    /// </summary>
    /// <param name="Value">
    /// Values can range from [0.0, 2.0].
    /// </param>
    /// <remarks>
    /// Note: The default value varies by model, see the Model.temperature attribute of the Model returned
    /// from the getModel function.
    /// </remarks>
    function Temperature(const Value: Double): TGenerationConfig;

    /// <summary>
    /// Optional. The maximum cumulative probability of tokens to consider when sampling.
    /// </summary>
    /// <remarks>
    /// <para>
    /// • The model uses combined Top-k and Top-p (nucleus) sampling. Tokens are sorted based on their
    /// assigned probabilities so that only the most likely tokens are considered. Top-k sampling
    /// directly limits the maximum number of tokens to consider, while Nucleus sampling limits the
    /// number of tokens based on the cumulative probability.
    /// </para>
    /// <para>
    /// • Note: The default value varies by Model and is specified by theModel.top_p attribute returned
    /// from the getModel function. An empty topK attribute indicates that the model doesn't apply
    /// top-k sampling and doesn't allow setting topK on requests.
    /// </para>
    /// </remarks>
    function TopP(const Value: Double): TGenerationConfig;

    /// <summary>
    /// Optional. The maximum number of tokens to consider when sampling.
    /// </summary>
    /// <remarks>
    /// <para>
    /// • Gemini models use Top-p (nucleus) sampling or a combination of Top-k and nucleus sampling.
    /// Top-k sampling considers the set of topK most probable tokens. Models running with nucleus
    /// sampling don't allow topK setting
    /// </para>
    /// <para>
    /// • Note: The default value varies by Model and is specified by theModel.top_p attribute returned
    /// from the getModel function. An empty topK attribute indicates that the model doesn't apply top-k
    /// sampling and doesn't allow setting topK on requests.
    /// </para>
    /// </remarks>
    function TopK(const Value: Integer): TGenerationConfig;

    /// <summary>
    /// Optional. Seed used in decoding. If not set, the request uses a randomly generated seed.
    /// </summary>
    function Seed(const Value: Integer): TGenerationConfig;

    /// <summary>
    /// Optional. Presence penalty applied to the next token's logprobs if the token has already been seen in the response.
    /// </summary>
    /// <remarks>
    /// This penalty is binary on/off and not dependant on the number of times the token is used (after the
    /// first). Use frequencyPenalty for a penalty that increases with each use.
    /// <para>
    /// • A positive penalty will discourage the use of tokens that have already been used in the response,
    /// increasing the vocabulary.
    /// </para>
    /// <para>
    /// • A negative penalty will encourage the use of tokens that have already been used in the response,
    /// decreasing the vocabulary.
    /// </para>
    /// </remarks>
    function PresencePenalty(const Value: Double): TGenerationConfig;

    /// <summary>
    /// Optional. Frequency penalty applied to the next token's logprobs, multiplied by the number of
    /// times each token has been seen in the respponse so far.
    /// </summary>
    /// <remarks>
    /// <para>
    /// • A positive penalty will discourage the use of tokens that have already been used, proportional
    /// to the number of times the token has been used: The more a token is used, the more difficult it
    /// is for the model to use that token again increasing the vocabulary of responses.
    /// </para>
    /// <para>
    /// • Caution: A negative penalty will encourage the model to reuse tokens proportional to the number
    /// of times the token has been used. Small negative values will reduce the vocabulary of a response.
    /// Larger negative values will cause the model to start repeating a common token until it hits the
    /// maxOutputTokens limit.
    /// </para>
    /// </remarks>
    function FrequencyPenalty(const Value: Double): TGenerationConfig;

    /// <summary>
    /// Optional. If true, export the logprobs results in response.
    /// </summary>
    function ResponseLogprobs(const Value: Boolean): TGenerationConfig;

    /// <summary>
    /// Optional. Only valid if responseLogprobs=True. This sets the number of top logprobs to return at
    /// each decoding step in the Candidate.logprobs_result.
    /// </summary>
    /// <param name="Value">
    /// The number must be in the range of [0, 20].
    /// </param>
    function Logprobs(const Value: Integer): TGenerationConfig;

    /// <summary>
    /// Optional. Enables enhanced civic answers. It may not be available for all models.
    /// </summary>
    function EnableEnhancedCivicAnswers(const Value: Boolean): TGenerationConfig;

    /// <summary>
    /// Optional. The speech generation config.
    /// </summary>
    function SpeechConfig(const Value: TspeechConfig): TGenerationConfig;

    /// <summary>
    /// Optional. Config for thinking features. An error will be returned if this field is set for models
    /// that don't support thinking.
    /// </summary>
    function ThinkingConfig(const Value: TThinkingConfig): TGenerationConfig;

    /// <summary>
    /// Optional. Config for image generation.
    /// </summary>
    /// <remarks>
    /// An error will be returned if this field is set for models that don't support these config options.
    /// </remarks>
    function ImageConfig(const Value: TImageConfig): TGenerationConfig;

    /// <summary>
    /// Optional. If specified, the media resolution specified will be used.
    /// </summary>
    function MediaResolution(const Value: TMediaResolutionType): TGenerationConfig;
  end;

implementation

{ TGenerationConfig }

function TGenerationConfig.CandidateCount(
  const Value: Integer): TGenerationConfig;
begin
  Result := TGenerationConfig(Add('candidateCount', Value));
end;

function TGenerationConfig.EnableEnhancedCivicAnswers(
  const Value: Boolean): TGenerationConfig;
begin
  Result := TGenerationConfig(Add('enableEnhancedCivicAnswers', Value));
end;

function TGenerationConfig.FrequencyPenalty(
  const Value: Double): TGenerationConfig;
begin
  Result := TGenerationConfig(Add('frequencyPenalty', Value));
end;

function TGenerationConfig.ImageConfig(
  const Value: TImageConfig): TGenerationConfig;
begin
  Result := TGenerationConfig(Add('imageConfig', Value.Detach));
end;

function TGenerationConfig.Logprobs(const Value: Integer): TGenerationConfig;
begin
  Result := TGenerationConfig(Add('logprobs', Value));
end;

function TGenerationConfig.MaxOutputTokens(const Value: Integer): TGenerationConfig;
begin
  Result := TGenerationConfig(Add('maxOutputTokens', Value));
end;

function TGenerationConfig.MediaResolution(
  const Value: TMediaResolutionType): TGenerationConfig;
begin
  Result := TGenerationConfig(Add('mediaResolution', Value.ToString));
end;

function TGenerationConfig.PresencePenalty(
  const Value: Double): TGenerationConfig;
begin
  Result := TGenerationConfig(Add('presencePenalty', Value));
end;

function TGenerationConfig.ResponseLogprobs(
  const Value: Boolean): TGenerationConfig;
begin
  Result := TGenerationConfig(Add('responseLogprobs', Value));
end;

function TGenerationConfig.ResponseMimeType(const Value: string): TGenerationConfig;
begin
  Result := TGenerationConfig(Add('responseMimeType', Value));
end;

function TGenerationConfig.ResponseModalities(
  const Value: TArray<TModalityType>): TGenerationConfig;
begin
  var JSONArray := TJSONArray.Create;
  for var Item in Value do
    JSONArray.Add(Item.ToString);
  Result := TGenerationConfig(Add('responseModalities', JSONArray));
end;

function TGenerationConfig.ResponseSchema(
  const Value: string): TGenerationConfig;
begin
  var JSON := TJSONObject.ParseJSONValue(Value);
  if Assigned(JSON) then
    Result := TGenerationConfig(Add('responseSchema', JSON))
  else
    raise GeminiException.CreateFmt('Invalid JSON: %s', [Value]);
end;

function TGenerationConfig.ResponseSchema(
  const Value: TJSONObject): TGenerationConfig;
begin
  Result := TGenerationConfig(Add('responseSchema', Value));
end;

function TGenerationConfig.ResponseSchema(
  const Value: TSchemaParams): TGenerationConfig;
begin
  Result := TGenerationConfig(Add('responseSchema', Value.Detach));
end;

function TGenerationConfig.Seed(const Value: Integer): TGenerationConfig;
begin
  Result := TGenerationConfig(Add('seed', Value));
end;

function TGenerationConfig.SpeechConfig(
  const Value: TspeechConfig): TGenerationConfig;
begin
  Result := TGenerationConfig(Add('speechConfig', Value.Detach));
end;

function TGenerationConfig.StopSequences(
  const Value: TArray<string>): TGenerationConfig;
begin
  Result := TGenerationConfig(Add('stopSequences', Value));
end;

function TGenerationConfig.Temperature(const Value: Double): TGenerationConfig;
begin
  Result := TGenerationConfig(Add('temperature', Value));
end;

function TGenerationConfig.ThinkingConfig(
  const Value: TThinkingConfig): TGenerationConfig;
begin
  Result := TGenerationConfig(Add('thinkingConfig', Value.Detach));
end;

function TGenerationConfig.TopK(const Value: Integer): TGenerationConfig;
begin
  Result := TGenerationConfig(Add('topK', Value));
end;

function TGenerationConfig.TopP(const Value: Double): TGenerationConfig;
begin
  Result := TGenerationConfig(Add('topP', Value));
end;

{ TPrebuiltVoiceConfig }

function TPrebuiltVoiceConfig.VoiceName(
  const Value: string): TPrebuiltVoiceConfig;
begin
  Result := TPrebuiltVoiceConfig(Add('voiceName', Value));
end;

{ TVoiceConfig }

class function TVoiceConfig.NewVoiceConfig(
  const VoiceName: string): TVoiceConfig;
begin
  Result := TVoiceConfig.Create
    .PrebuiltVoiceConfig(
      TPrebuiltVoiceConfig.Create.VoiceName(VoiceName)
     )
end;

function TVoiceConfig.PrebuiltVoiceConfig(
  const Value: TPrebuiltVoiceConfig): TVoiceConfig;
begin
  Result := TVoiceConfig(Add('prebuiltVoiceConfig', Value.Detach));
end;

{ TSpeechConfig }

function TSpeechConfig.LanguageCode(const Value: string): TSpeechConfig;
begin
  Result := TSpeechConfig(Add('languageCode', Value));
end;

function TSpeechConfig.MultiSpeakerVoiceConfig(
  const Value: TMultiSpeakerVoiceConfig): TSpeechConfig;
begin
  Result := TSpeechConfig(Add('multiSpeakerVoiceConfig', Value.Detach));
end;

function TSpeechConfig.VoiceConfig(const Value: TVoiceConfig): TSpeechConfig;
begin
  Result := TSpeechConfig(Add('voiceConfig', Value.Detach));
end;

{ TSpeakerVoiceConfig }

class function TSpeakerVoiceConfig.NewSpeakerVoiceConfig(const Speaker: string;
  const VoiceConfig: TVoiceConfig): TSpeakerVoiceConfig;
begin
  Result := TSpeakerVoiceConfig.Create
    .Speaker(Speaker)
    .VoiceConfig(VoiceConfig)
end;

class function TSpeakerVoiceConfig.NewSpeakerVoiceConfig(const Speaker,
  VoiceName: string): TSpeakerVoiceConfig;
begin
  Result := TSpeakerVoiceConfig.Create
    .Speaker(Speaker)
    .VoiceConfig(
      TVoiceConfig.NewVoiceConfig(VoiceName)
      )
end;

function TSpeakerVoiceConfig.Speaker(const Value: string): TSpeakerVoiceConfig;
begin
  Result := TSpeakerVoiceConfig(Add('speaker', Value));
end;

function TSpeakerVoiceConfig.VoiceConfig(
  const Value: TVoiceConfig): TSpeakerVoiceConfig;
begin
  Result := TSpeakerVoiceConfig(Add('voiceConfig', Value.Detach));
end;

{ TMultiSpeakerVoiceConfig }

function TMultiSpeakerVoiceConfig.SpeakerVoiceConfigs(
  const Value: TArray<TSpeakerVoiceConfig>): TMultiSpeakerVoiceConfig;
begin
  var JSONArray := TJSONArray.Create;
  for var Item in Value do
    JSONArray.Add(Item.Detach);
  Result := TMultiSpeakerVoiceConfig(Add('speakerVoiceConfigs', JSONArray));
end;

{ TThinkingConfig }

function TThinkingConfig.IncludeThoughts(const Value: Boolean): TThinkingConfig;
begin
  Result := TThinkingConfig(Add('includeThoughts', Value));
end;

function TThinkingConfig.ThinkingBudget(const Value: Integer): TThinkingConfig;
begin
  Result := TThinkingConfig(Add('thinkingBudget', Value));
end;

function TThinkingConfig.ThinkingLevel(
  const Value: TThinkingLevelType): TThinkingConfig;
begin
  Result := TThinkingConfig(Add('thinkingLevel', Value.ToString));
end;

{ TImageConfig }

function TImageConfig.AspectRatio(const Value: string): TImageConfig;
begin
  Result := TImageConfig(Add('aspectRatio', Value));
end;

function TImageConfig.ImageSize(const Value: string): TImageConfig;
begin
  Result := TImageConfig(Add('imageSize', Value));
end;

end.
